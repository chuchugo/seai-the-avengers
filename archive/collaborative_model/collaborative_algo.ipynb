{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train KNN model using Cosine similarity with user rating data\n",
    "\n",
    "We want to choose the similar user to every user.\n",
    "Find the similar user by all user ratings.(calculate by cosine similarity of person A's rating to person B's ratings)\n",
    "If the ratings are similar, these two people have similar tatse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99470/2485621834.py:3: DtypeWarning: Columns (0,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"kafka-consumer/data/user_ratings_ongoing.csv\",names=columns) #with 370k data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>468282</td>\n",
       "      <td>jurassic+park+1993</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>263188</td>\n",
       "      <td>pulp+fiction+1994</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>296237</td>\n",
       "      <td>life+is+rosy+1987</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>255439</td>\n",
       "      <td>speed+1994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>283675</td>\n",
       "      <td>the+shawshank+redemption+1994</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId                        movieId rating\n",
       "1  468282             jurassic+park+1993      4\n",
       "2  263188              pulp+fiction+1994      3\n",
       "3  296237              life+is+rosy+1987      5\n",
       "4  255439                     speed+1994      4\n",
       "5  283675  the+shawshank+redemption+1994      4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = [\"userId\",\"movieId\",\"rating\"]\n",
    "df = pd.read_csv(\"kafka-consumer/data/user_ratings_ongoing.csv\",names=columns) #with 370k data\n",
    "df = df[1:]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "df = df[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "\n",
    "# Loads rating data for training \n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[[\"userId\", \"movieId\", \"rating\"]], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use user-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True,\n",
    "}\n",
    "\n",
    "# Training algorithm using KNNwithMeans, to find the closest users to user A\n",
    "algo = KNNWithMeans(sim_options=sim_options) #(k=40, min_k=1, sim_options={}, verbose=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x7f66d1b4e4c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split training, validation dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "trainset, validationset = train_test_split(data, test_size=.20)\n",
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7f6696834d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(trainset)\n",
    "#predictions = algo.test(validationset)\n",
    "#accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting result\n",
    "def formatting_result(predictions): \n",
    "    columns = [\"userId\", \"movieId\",\"rating\",\"est\",\"details\"]\n",
    "    df_result = pd.DataFrame(predictions,columns = columns)\n",
    "    df_result = df_result[[\"userId\", \"movieId\",\"rating\",\"est\"]]\n",
    "    # add rank\n",
    "    # each user, we rank the rightest ratings for website recommendations\n",
    "    df_result[\"rank\"] = df_result.groupby(\"userId\")[\"est\"].rank(\"dense\", ascending=False)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get movie list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMovieFile():\n",
    "    # read all the movie ids\n",
    "    import pandas as pd\n",
    "    df_movies = pd.read_csv(\"kafka-consumer/data/clean_data_1.csv\")\n",
    "    df_movies.shape\n",
    "\n",
    "    # df_movies.head()\n",
    "    ser_movies = df_movies[\"id\"] \n",
    "    df_movies.head(5)\n",
    "    return ser_movies\n",
    "ser_movies = getMovieFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the recmmoendation for a user, create userTestSet for prediction\n",
    "    # list of tuples\n",
    "    #[('469629', 'casino+1995', 5.0),\n",
    "    # ('871227', 'bedknobs+and+broomsticks+1971', 3.0)]\n",
    "\n",
    "def makeSet(userid): # input should be a number instead of str\n",
    "    userid = str(userid)\n",
    "    userTestSet = list()\n",
    "    for movie in ser_movies:\n",
    "        tuple = (userid, movie, 0)\n",
    "        userTestSet.append(tuple)\n",
    "    return userTestSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#choose top 20 ratings of movies for one user\n",
    "def chooseTop20(userid,df_result):\n",
    "    is_user = df_result[\"userId\"]== str(userid)\n",
    "    df_user = df_result[is_user]\n",
    "    df_user = df_user.sort_values([\"rank\"], ascending=True)\n",
    "    # print(df_user)\n",
    "    if (df_user.shape[0]>20):\n",
    "        df_user  = df_user[:20]\n",
    "    return df_user\n",
    "\n",
    "# For cold start users/ users who didnt occur in the rating file\n",
    "# give them the most popular movies \n",
    "def Top20inAllMovie(df):\n",
    "    # the movie occured the most in the movie rating file\n",
    "    df_top20inAll = df[\"movieId\"].value_counts()[:20]\n",
    "    return df_top20inAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictAndRecommend(userId):\n",
    "    userId = str(userId)\n",
    "    # check if the user didn't rate before, return top most popular movie directly\n",
    "    if userId not in df[\"userId\"].values:\n",
    "        return Top20inAllMovie(df)\n",
    "    # if the user has rated before, predict her Top 20 rated movies \n",
    "    userTestSet = makeSet(userId)\n",
    "    predictions2 = algo.test(userTestSet)\n",
    "    df_result = formatting_result(predictions2)\n",
    "    df_user = chooseTop20(userId,df_result)\n",
    "    df.to_csv('model1_data/out.csv')\n",
    "    user_movieList = df_user['movieId'].tolist()\n",
    "    return user_movieList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['up+2009',\n",
       " 'sleepless+in+seattle+1993',\n",
       " 'about+schmidt+2002',\n",
       " 'lock_+stock+and+two+smoking+barrels+1998',\n",
       " 'the+sound+of+music+1965',\n",
       " 'a+christmas+story+1983',\n",
       " 'the+avengers+2012',\n",
       " 'the+lion+king+1994',\n",
       " 'forrest+gump+1994',\n",
       " 'the+child+2005',\n",
       " 'copycat+1995',\n",
       " 'the+great+dictator+1940',\n",
       " 'the+rock+1996',\n",
       " 'austin+powers+the+spy+who+shagged+me+1999',\n",
       " 'some+folks+call+it+a+sling+blade+1994',\n",
       " 'empire+of+the+sun+1987',\n",
       " 'the+usual+suspects+1995',\n",
       " 'sleepy+hollow+1999',\n",
       " 'babe+1995',\n",
       " 'beauty+and+the+beast+1991']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test with user \n",
    "predictAndRecommend(468282)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#TODO: prediction accuracy : split the set. partly is wachted, partly is prepared to watch\n",
    "        # compare with prepare to wach with my recommendation \n",
    "#TODO5 : havent filter out the movie the user rated before\n",
    "\n",
    "\n",
    "#WAIT : update movie data clean data\n",
    "#WAIT : update more rating data\n",
    "\n",
    "#finished : cold start user give them the most popular movies \n",
    "#fihished : what if the user id is not in the rating dataset\n",
    "\n",
    "#def find_most_poplular20():\n",
    "    # the movie occured the most in the movie rating file\n",
    "\n",
    "# for how long would the rating data covers all user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User size:\n",
    "\n",
    " currently we have 66k users.\n",
    "\n",
    " total is about 1 million customers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Tuning the Algorithm Parameters\n",
    "https://realpython.com/build-recommendation-engine-collaborative-filtering/\n",
    "\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True],\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although collaborative Filtering is very commonly used in recommenders, some of the challenges that are faced while using it are the following:\n",
    "\n",
    "Collaborative filtering can lead to some problems like cold start for new items that are added to the list. Until someone rates them, they don’t get recommended.\n",
    "\n",
    "Data sparsity can affect the quality of user-based recommenders and also add to the cold start problem mentioned above.\n",
    "\n",
    "Scaling can be a challenge for growing datasets as the complexity can become too large. Item-based recommenders are faster than user-based when the dataset is large.\n",
    "\n",
    "With a straightforward implementation, you might observe that the recommendations tend to be already popular, and the items from the long tail section might get ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7119ec9dcb203142e35949af8df67d46e37fa7cacb15339a197f0fb4667d0ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

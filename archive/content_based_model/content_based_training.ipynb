{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES AND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "from ast import literal_eval\n",
    "from datetime import datetime\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GATHERING DATA\")\n",
    "data = pd.read_csv(\"../kafka-consumer/data/movie_data_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns == ['id', 'tmdb_id', 'imdb_id', 'title', 'original_title', 'adult',\n",
    "       'belongs_to_collection', 'budget', 'genres', 'homepage',\n",
    "       'original_language', 'overview', 'popularity', 'poster_path',\n",
    "       'production_companies', 'production_countries', 'release_date',\n",
    "       'revenue', 'runtime', 'spoken_languages', 'status', 'vote_average',\n",
    "       'vote_count', 'message']\n",
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA PREPROCESSING\")\n",
    "\n",
    "# Modify belongs_to_collection if there is a collection the movie belongs to\n",
    "for i in range(len(data['belongs_to_collection'])):\n",
    "    if data['belongs_to_collection'][i] != \"{}\":\n",
    "        collection = data['belongs_to_collection'][i].split(\",\")[1].split(\"'\")[-2].replace(\"Collection\", \"\").strip(\" :\\\"\")\n",
    "        data.at[i, 'belongs_to_collection'] = collection\n",
    "    if data['belongs_to_collection'][i] == \"{}\":\n",
    "        data.at[i, 'belongs_to_collection'] = \"\"\n",
    "\n",
    "# Normalize popularity between range of 0 and 1\n",
    "for i in range(len(data['popularity'])):\n",
    "    data.at[i, 'popularity'] = data['popularity'][i] / data['popularity'].max() * 100\n",
    "\n",
    "# Named Entity Recognition on overview + POS Tagging\n",
    "# verb VERB + adverb ADV + adjective ADJ\n",
    "NLP = spacy.load(\"en_core_web_sm\")\n",
    "for i in range(len(data['overview'])):\n",
    "    if isinstance(data['overview'][i], float):\n",
    "        data.at[i, 'overview'] = \"\"\n",
    "    else:\n",
    "        raw_text = NLP(data['overview'][i])\n",
    "\n",
    "        ner_list = []\n",
    "        for word in raw_text.ents:\n",
    "            if word.label_ != \"PERSON\":\n",
    "                ner_list.append(word.text)\n",
    "\n",
    "        pos_list = []\n",
    "        for word in raw_text:\n",
    "            if word.pos_ == \"VERB\" or word.pos_ == \"ADV\" or word.pos_ == \"ADJ\":\n",
    "                pos_list.append(word.text)\n",
    "\n",
    "        overview_list = list(set(ner_list + pos_list))\n",
    "        overview = ' '.join([word for word in overview_list])\n",
    "\n",
    "        data.at[i, 'overview'] = overview\n",
    "\n",
    "\n",
    "# Convert date form to year\n",
    "for i in range(len(data['release_date'])):\n",
    "    if isinstance(data['release_date'][i], float):\n",
    "        data.at[i, 'release_date'] = \"\"\n",
    "    else:\n",
    "        row = data['release_date'][i].split('-')\n",
    "        year, month, date = row[0], datetime.strptime(row[1], \"%m\").strftime(\"%B\"), row[2]\n",
    "        data.at[i, 'release_date'] = month + \" \" + date + \", \" + year\n",
    "data = data[data['release_date'] != \"\"]\n",
    "\n",
    "# Delete rows where message = \"movie not found\"\n",
    "data = data[data.message != \"movie not found\"]\n",
    "\n",
    "# Delete rows where status = \"Rumored\" or nan\n",
    "data = data[data.status != \"Rumored\"]\n",
    "data = data.dropna(subset=['status'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the names of all the genres attached to each movie\n",
    "data['genres'] = data['genres'].apply(literal_eval)\n",
    "data['genres'] = data['genres'].apply(lambda x: [i['name'].lower() for i in x])\n",
    "data['genres'] = data['genres'].apply(lambda x: [i.replace(' ','') for i in x])\n",
    "\n",
    "# Grabbing the names of all the production_companies attached to each movie\n",
    "data['production_companies'] = data['production_companies'].apply(literal_eval)\n",
    "data['production_companies'] = data['production_companies'].apply(lambda x: [i['name'].lower() for i in x])\n",
    "data['production_companies'] = data['production_companies'].apply(lambda x: [i.replace(' ','') for i in x])\n",
    "\n",
    "# Grabbing the names of all the production_countries attached to each movie\n",
    "data['production_countries'] = data['production_countries'].apply(literal_eval)\n",
    "data['production_countries'] = data['production_countries'].apply(lambda x: [i['name'].lower() for i in x])\n",
    "data['production_countries'] = data['production_countries'].apply(lambda x: [i.replace(' ','') for i in x])\n",
    "\n",
    "# Grabbing the names of all the spoken_languages attached to each movie\n",
    "data['spoken_languages'] = data['spoken_languages'].apply(literal_eval)\n",
    "data['spoken_languages'] = data['spoken_languages'].apply(lambda x: [i['name'].lower() for i in x])\n",
    "data['spoken_languages'] = data['spoken_languages'].apply(lambda x: [i.replace(' ','') for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep necessary columns\n",
    "data = data[['id', 'title', 'adult', 'belongs_to_collection', 'genres', 'overview', 'popularity',\n",
    "            'production_companies', 'production_countries', 'release_date', 'spoken_languages', 'status']]\n",
    "\n",
    "# data = data.drop(['popularity', 'release_date'], axis=1)\n",
    "data['metadata'] = data.apply(lambda x: str(x['title']) + ' ' + str(x['adult']) + ' ' + str(x['belongs_to_collection']) + ' '.join(x['genres']) \n",
    "                                        + ' ' + str(x['overview']) + ' ' + str(x['popularity']) + ' ' + ' '.join(x['production_companies']) \n",
    "                                        + ' ' + ' '.join(x['production_countries']) + ' ' + str(x['release_date']) + ' ' \n",
    "                                        + ' '.join(x['spoken_languages']) + ' ' + str(x['status']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns\n",
    "len(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WRITING CLEAN DATA TO FILE\")\n",
    "data.to_csv(\"../kafka-consumer/data/2_clean_data1.csv\", index=False)\n",
    "\n",
    "print(len(data['id'])) \n",
    "\n",
    "print(\"TRAINING THE MODEL\")\n",
    "\n",
    "count_vec = CountVectorizer(stop_words='english')\n",
    "count_vec_matrix = count_vec.fit_transform(data['metadata'])\n",
    "cosine_sim_matrix = cosine_similarity(count_vec_matrix, count_vec_matrix)\n",
    "\n",
    "print(cosine_sim_matrix.shape)\n",
    "\n",
    "file = open(\"../kafka-consumer/model/2_saved_model1\", \"ab\")\n",
    "pickle.dump(cosine_sim_matrix, file)\n",
    "file.close()\n",
    "\n",
    "print(\"...DONE!!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
